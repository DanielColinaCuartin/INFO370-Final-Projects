{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Play Store App Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What relationship does a title have on the overall success of an app? If you are a software developer with an awesome Google Play Store application, what words could you use in the title to help your app succeed? \n",
    "\n",
    "The phrase \"don't judge a book by it's cover\" is perhaps the least used advice in America. And why not? With the sheer amount of information, books, apps, and articles it's practically impossible to make an informed decision on every single candidate. So it seems reasonable to pick from a few that catch your attention, and in the world of mobile applications the only advertisement you may see is a few words and an icon. \n",
    "\n",
    "So how can we as developers best entice people to our applications, using the few characters afforded in an application name? That is what we are setting out to learn. Through statistical and machine learning models, we hope to learn about the correlation between words in an app's title and that app's success, specifically in terms of user downloads.\n",
    "\n",
    "Naming decisions aren't the only decisions app developers/marketers face though, so we will also explore the effect an app's category, size, and other attributes have on installs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is coming from Kaggle.com, it includes web-scraped features from the Google Play Store. Lavanya Gupta maintains the dataset, and last updated it a month ago, February 2019. Although there is a great deal of Apple datasets available, Google has a dynamic play store system that makes web scraping more challenging. But, with the data now available to us we can use it to gain insight into what Google Play Apps are like on a high level.\n",
    "\n",
    "This data contains information for apps last gathered in August of 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of features\n",
    "\n",
    "<img src=\"img/rating_dist.png\" style=\"width: 7in;\"/>\n",
    "\n",
    "We have a total of 9,360 ratings, and a mean rating of 4.191838 with a standard deviation of 0.515263. The individual ratings are integers in the form of 1 to 5 stars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories\n",
    "\n",
    "<img src=\"img/categories_dist.png\" style=\"width: 7in;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of 33 categories represented, and the three most popular apps (to develop) by far are Family, Game, and Productivity, each with over 750 apps in the play store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Installs (Ranges, not hard numbers)\n",
    "\n",
    "The biggest challenge with this dataset is that we do not have hard numbers for the number of installs for a given app. As an app becomes more popular, we lose precision as to how many people have downloaded that app. The way the data is presented in the app store, if it has 15,000 downloads the app will display that it has \"10,000+\" downloads. If it has 250,000 downloads the data may just represent this as \"100,000+\" downloads. This is probably for a variety of reasons, including user/developer privacy. But it does make regression and establishing numerical relationships challenging.\n",
    "\n",
    "We have decided to treat the installs feature as a \"minimum installs\" feature instead. So if any of our models predicts that an app would have say 15,000 installs, it would be more correct to say that it is likely the app would have at a minimum 10,000-15,000 installs. \n",
    "\n",
    "The reason we don't predict which range the app would fall in is because it would be for a computer to establish the order of significance of the features is \"100+\" better or worse than \"10,000+\"? And since the ranges aren't distributed evenly (We have a range of 0-50 and a range from 10,000 to 99,999 installs), we would need to indicate to our models the relative size of the ranges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Popular Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table and Visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Modeling\n",
    "\n",
    "The original data had 9,367 apps described, but 7 of those had pretty NA values (incomplete observations) so we dropped them since our dataset was large enough to minimize the problems of dropping a few rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at relationships of other features to installs, to get a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy and types of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "\n",
    "https://www.kaggle.com/lava18/google-play-store-apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
